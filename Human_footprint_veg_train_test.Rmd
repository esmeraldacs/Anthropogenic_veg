---
title: "Untitled"
output: html_document
date: "2024-11-28"
---

```{r}
library(tidyverse)
library(sf)
library(raster)
```


```{r}
pmodern <- readRDS("H:/My Drive/Alex_lab_databases/Pmodern_revised_ecol.rds")
```


```{r}
pmp_meta <- pmodern$pmp_meta
pmp_pollen <- pmodern$pmp_pollen
pmp_ecological <- pmodern$pmp_ecological
```


```{r}
latam_polygon <- rnaturalearth::ne_countries(scale = 'large', returnclass = "sf") |>
  dplyr::filter(name %in% c("Mexico", "Guatemala", "Belize", "El Salvador", "Honduras", "Nicaragua", "Costa Rica", "Panama", "Dominican Rep.","Cuba", "Colombia", "Venezuela", "Ecuador", "Guyana", "Suriname", "French Guiana", "Peru", "Brazil", "Argentina", "Bolivia", "Uruguay", "Paraguay", "Chile","Puerto Rico","Jamaica")) |>
  sf::st_union() |>
  sf::st_crop(ymin = -34, ymax = 22, xmin=-106, xmax=-35) |>
  sf::st_as_sf() 

ggplot2::ggplot() + ggplot2::geom_sf(data = latam_polygon) + ggplot2::theme_minimal()
```


Primero volvemos a extraer los valores exacto y con buffer de 12km radio para cada muestra de polen
```{r}
output_file <- "H:/My Drive/Alex_lab_databases/Output_data/HFP2009_reprojected.tif"

raster_raw <- raster::raster(output_file)

footprint_raster <- raster_raw |>
  raster::crop(raster::extent(-108, -33, -40, 25)) |> 
  raster::mask(latam_polygon)
```


```{r}
# Extract exact point values
pmp_ecological <- pmp_ecological |>
  left_join(pmp_meta) |>
  dplyr::select(ID,hill_n2,lon,lat) |>
  mutate(hfp_exact = extract(footprint_raster, cbind(lon, lat))) |>
# Extract values within the buffer (12 km = 12000 meters) and compute the mean
  mutate(hfp_12km = extract(footprint_raster, cbind(lon, lat), buffer = 12000, fun = mean),
         hfp_24km = extract(footprint_raster, cbind(lon, lat), buffer = 24000, fun = mean))
```


#--------------
```{r}
maps <- sf::st_read("C:/Users/esmer/UoR/latam_climate_reconstruction/Input/Precipitation_polygon/my_new_polygon.shp") 

maps1 <- sf::st_intersection(maps, latam_polygon) |> 
  filter(!Value %in% c(0,14,23,24,10,9,16)) |>
   filter(!(Value == 18 & sf::st_geometry_type(geometry) == "MULTIPOLYGON")) |>
   rename(region = Value)


plot0 <- ggplot2::ggplot() + 
  ggplot2::geom_sf(data = latam_polygon, fill="transparent") +  
  geom_sf(data = maps1, aes(fill=region, colour=region)) +
  jcolors::scale_color_jcolors(palette = "pal9") +
  jcolors::scale_fill_jcolors(palette = "pal9") +
  theme_test()

plot0
```



```{r}
# Convert pmp_meta to sf object
pmp_meta_sf <- pmp_meta %>%
  sf::st_as_sf(coords = c("lon", "lat"), crs = 4326)  # Assuming lon/lat is in WGS84 (EPSG:4326)

# Perform spatial join to find which Value corresponds to each point
pmp_meta_sf <- pmp_meta_sf %>%
  sf::st_join(maps1, join = sf::st_within) %>% # Join based on spatial location
  filter(!is.na(region))

# View the result
pmp_meta_sf 
```


```{r}
pmp_meta_zone <- pmp_meta_sf %>%
  mutate(
    longitude = sf::st_coordinates(.)[, 1],   # Extract longitude
    latitude = sf::st_coordinates(.)[, 2]     # Extract latitude
  ) %>%
  sf::st_drop_geometry()
```



```{r}
ggplot2::ggplot() + 
  ggplot2::geom_sf(data = latam_polygon) + 
  geom_point(data=pmp_meta_zone, aes(x=longitude, y=latitude, fill=region, colour=region)) +
  jcolors::scale_color_jcolors(palette = "pal9") +
  jcolors::scale_fill_jcolors(palette = "pal9") +
  ggplot2::theme_minimal()
```





Chunk que hay que correr solo si queremos el plot
```{r}
raster_df <- as.data.frame(footprint_raster, xy = TRUE) |>
  filter(!is.na(HFP2009_reprojected))



plot0.2 <- ggplot() +
  ggplot2::geom_sf(data = latam_polygon,fill="gray95") +
  geom_tile(data = raster_df, aes(x = x, y = y, fill = HFP2009_reprojected)) +
  #scale_fill_viridis_c(name = "Value", option = "plasma") +
  #jcolors::scale_fill_jcolors_contin(palette = "pal12", bias = 0.8) +
  scico::scale_fill_scico(palette = "lipari") +
  labs(x = NULL,
       y = NULL,
       fill  = "HFP") +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0)) +
  ggspatial::annotation_north_arrow(location = "tr", which_north = "true",height = unit(4.8, "mm"), width = unit(4.8, "mm"), pad_x = unit(2, "mm"), pad_y = unit(2, "mm"),style = ggspatial::north_arrow_nautical(fill = c("grey40", "white"),line_col = "grey20", text_family = "Book Antiqua",text_size = 5.5)) +  # "Mongolian Baiti"
  annotate(geom = "text", x = -98.3, y = 2, label = "Pacific", 
    fontface = "italic", color = "gray25", size = 2) +
  annotate(geom = "text", x = -98.4, y = 0, label = "Ocean", 
    fontface = "italic", color = "gray25", size = 2) +
  theme(panel.background = element_rect(fill="white",color="transparent"),
        panel.border = element_rect(fill="transparent",color="black"),
        panel.grid = element_blank(),
        axis.title.x = element_text(size=7.5,color = "black"),
        axis.title.y = element_text(size=7.5, angle=90),
        axis.text.x = element_text(size=7.5),
        axis.text.y = element_text(size=7.5),
       # axis.ticks = element_blank(),
        legend.key.size = unit(0.20,"cm"),
        legend.text.align = 0,
        legend.text=element_text(size=6.5),
        legend.title.align = 0.5,
        legend.title = element_text(size = 6.5),
        legend.margin = margin(unit = "cm", t=0.05,r=0.08,b=0.15,l=0.08),
        legend.box.background = element_rect(fill=alpha('white', 0.2),color="gray30",size = 0.15,),
        legend.background = element_rect(fill=alpha('white', 0.45),color="gray30",size = 0.25),
        legend.position = c(0.1,0.2))

plot0.2
```


```{r}
ggsave(plot = plot0.2, "G:/My Drive/Postdoc UNAM docs/Renovación posdoc DGAPA/mapa_HFP_lipari.jpg", units = "cm", height = 10, width = 10)
```


Extracting raster values within each polygon
```{r}
maps1 <- st_transform(maps1, crs = st_crs(footprint_raster)) # Ensure that the CRS of maps1 matches the CRS of the raster

cell_indices <- extract(footprint_raster, maps1, cellnumbers = TRUE) # Extract cell numbers (indices) within each polygon

# Function to extract the coordinates (lat-lon) and values for each polygon
extract_pixel_info <- function(cell_indices, polygon_value) {
  if (length(cell_indices) == 0) return(NULL)  # Handle empty result
  # Get the pixel locations (lat-lon) for the cell indices
  pixel_coords <- xyFromCell(footprint_raster, cell_indices)
  # Get the raster values at these pixel locations
  pixel_values <- extract(footprint_raster, pixel_coords)
  
  # Return data with the polygon's region, but filter out NAs
  data <- data.frame(lon = pixel_coords[, 1], lat = pixel_coords[, 2], value = pixel_values, region = polygon_value)
  return(data[!is.na(data$value), ])  # Filter out rows where value is NA
}

# Apply the function to all polygons and include the polygon region in each case
pixel_data <- mapply(extract_pixel_info, cell_indices, maps1$region, SIMPLIFY = FALSE)

# Split the results by 'region' to prevent a massive dataframe
# This will create a list of dataframes, each corresponding to a different 'region'
pixel_data_split <- split(do.call(rbind, pixel_data), do.call(c, lapply(pixel_data, function(x) x$region)))
```



```{r}
saveRDS(pixel_data_split, "Output_data_human_footprint/pixel_data_split.rds")
```



```{r}
pixel_data_split <- readRDS("Output_data_human_footprint/pixel_data_split.rds")
```



```{r}
# Example: To access the dataframe for Value 21
example <- pixel_data_split[["12"]]
example |>
  ggplot(aes(x=lon, y=lat, fill=value, colour=value)) +
  geom_tile() +
  theme()

example <- pixel_data_split[["15"]]
example |>
  ggplot(aes(x=lon, y=lat, fill=value, colour=value)) +
  geom_tile() +
  theme()
```



Plot all zones
```{r}
# Convert raster values to a dataframe with lat-lon and raster values
raster_df <- as.data.frame(footprint_raster, xy = TRUE, na.rm = TRUE)
colnames(raster_df) <- c("lon", "lat", "value")

# Create a data frame for each region from the pixel_data_split list
# Combine all the dataframes into one (with lat, lon, value, and region)
pixel_data_combined <- do.call(rbind, lapply(names(pixel_data_split), function(value) {
  df <- pixel_data_split[[value]]
  df$region <- value
  return(df)
}))

# Merge the raster data with the latam_polygon data
latam_polygon <- st_transform(latam_polygon, crs = st_crs(footprint_raster))

# Plot using ggplot2
plot1 <- ggplot() +
  #geom_sf(data = latam_polygon, fill = "gray95", color = "black") +  # Plot the polygon
  geom_raster(data = pixel_data_combined, aes(x = lon, y = lat, fill = value)) +  # Plot the raster values
  scico::scale_fill_scico(palette = "lipari") +
 # scale_fill_viridis_c() +  # Use a color scale for the raster values
  facet_wrap(~ region, ncol=1, scales = "free") +  # Create a facet for each 'Value'
  labs(fill = "Pressure", x=NULL, y=NULL) +
  theme(panel.background = element_rect(fill="white",color="transparent"),
        panel.border = element_rect(fill="transparent",color="black"),
        panel.grid = element_blank(),
        axis.text.x = element_text(size=7.5),
        axis.text.y = element_text(size=7.5),
        strip.text = element_text(size = 7.5, hjust = 0, vjust = 0),
        strip.background = element_rect(fill="transparent", colour="transparent"),
        legend.key.size = unit(0.20,"cm"),
        legend.text.align = 0,
        legend.text=element_text(size=6.5),
        legend.title.align = 0.5,
        legend.title = element_text(size = 6.5),
        legend.margin = margin(unit = "cm", t=0.05,r=0.08,b=0.15,l=0.08),
        legend.box.background = element_rect(fill=alpha('white', 0.2),color="gray30",size = 0.15,),
        legend.background = element_rect(fill=alpha('white', 0.45),color="gray30",size = 0.25))

plot1
```



```{r}
ggsave(plot = plot1, "G:/My Drive/Postdoc UNAM docs/Renovación posdoc DGAPA/plot_zones.pdf", units = "cm", width = 7, height=26)
```



```{r}
# Combine all the data back into a single dataframe (after splitting by region)
# You can use `do.call(rbind, pixel_data_split)` to combine them into a single dataframe
pixel_df <- do.call(rbind, pixel_data_split)

# Calculate the median of 'value' for each 'Value'
median_values <- pixel_df %>%
  group_by(region) %>%
  summarise(median_value = median(value, na.rm = TRUE))

# Plot histogram of the 'value' column for each 'region' as a separate facet
plot3 <- ggplot(pixel_df, aes(x = value)) +
  geom_histogram(binwidth = 1, color = "black", fill = "skyblue", alpha = 0.7, linewidth = 0.2) +  # Adjust binwidth as needed
  facet_wrap(~ region, scales = "free", ncol=1) +  
  geom_vline(data = median_values, aes(xintercept = median_value), color = "red", linetype = "dashed", size = 1) +  # Add vertical line at median
  labs(x = NULL, y = NULL) +
  scale_x_continuous(expand = c(0,0)) +
  theme(panel.background = element_rect(fill="white",color="transparent"),
        panel.border = element_rect(fill="transparent",color="black"),
        panel.grid = element_blank(),
        axis.text.x = element_text(size=7.5),
        axis.text.y = element_text(size=7.5),
        strip.text = element_text(size = 7.5, hjust = 0, vjust = 0),
        strip.background = element_rect(fill="transparent", colour="transparent"),
        legend.key.size = unit(0.20,"cm"),
        legend.text.align = 0,
        legend.text=element_text(size=6.5),
        legend.title.align = 0.5,
        legend.title = element_text(size = 6.5),
        legend.margin = margin(unit = "cm", t=0.05,r=0.08,b=0.15,l=0.08),
        legend.box.background = element_rect(fill=alpha('white', 0.2),color="gray30",size = 0.15,),
        legend.background = element_rect(fill=alpha('white', 0.45),color="gray30",size = 0.25))


plot3
```



```{r}
ggsave(plot = plot3, "G:/My Drive/Postdoc UNAM docs/Renovación posdoc DGAPA/plot_histograms.pdf", units = "cm", width = 6.5, height=26)
```


```{r}
# Calculate the median of the 'value' column for each 'Value' in the split data
medians_per_value <- lapply(pixel_data_split, function(df) median(df$value, na.rm = TRUE))

# Convert the result into a dataframe for easier reading
medians_df <- data.frame(region = names(medians_per_value), Median_Value = unlist(medians_per_value))

# View the result
medians_df
```


```{r}
pmp_usage_meta <- pmp_meta_zone |>
 # left_join(pmp_ecological) |>
  left_join(medians_df) |>
  rename(median_human_footprint = Median_Value) |>
  mutate(class_exact = case_when(human_footprint_exact < median_human_footprint ~ "NO", TRUE ~ "YES"),
         class_12km = case_when(human_footprint_avg12km < median_human_footprint ~ "NO", TRUE ~ "YES"))

pmp_usage_meta
```




```{r}
pmp_usage_meta |>
  filter(region == 15) |>
  ggplot(aes(x=longitude, y=latitude,fill=class_exact, colour=class_exact)) +
  geom_point()


pmp_usage_meta |>
  filter(region == 15) |>
  ggplot(aes(x=longitude, y=latitude,fill=class_12km, colour=class_12km)) +
  geom_point()
```




```{r}
pmp_usage1 <- pmp_usage_meta |>
  dplyr::select(ID, region, class_12km) |>
  left_join(pmp_pollen)

pmp_usage1
```



```{r}
# Split the dataframe into a list of dataframes by 'Value'
pmp_usage_split <- split(pmp_usage1, pmp_usage1$region)

# Access individual dataframes from the list, e.g., for Value "13":
pmp_usage_split[["13"]]
```


```{r}
saveRDS(pmp_usage_split, "Output_data_human_footprint/pmp_usage_split.rds")
```



```{r}
# Set a seed for reproducibility
set.seed(1243)
# Apply sampling directly to each dataframe in the list
pmp_usage_sampled <- pmp_usage_split %>%
  map(~ .x %>%
        group_by(class_12km) %>%
        slice_sample(prop = 0.7) %>%
        ungroup())

# Check the result for a specific Value, e.g., "13"
pmp_usage_sampled[["13"]]
```


Filtrar taxa que ocurren en menos de 3 muestas, en este momento no lo realizamos, porque necesitariamos, pienso, re-escalar a 100%
```{r}
# Pre-filtered auxiliary data
#aux1 <- pmp_usage_sampled[["13"]] |>
  #pivot_longer(cols = -c(region, class_12km, ID)) |>
  #filter(value > 0) |>
  #count(class_12km, region, name) |>
  #filter(n >= 2) |>
  #dplyr::select(-n)

# Main dataset with auxiliary filtering applied
#pmp_usage_sampled_13 <- pmp_usage_sampled[["13"]] |>
  #pivot_longer(cols = -c(ID, region, class_12km)) |>
  #inner_join(aux1, by = c("region", "class_12km", "name")) |>
  #filter(value > 0) |>
  #group_by(ID) |>
  #mutate(value = (value / sum(value)) * 100) |>
  #ungroup()
```




```{r}
n_samples_train <- pmp_usage_split %>%
  map(~ .x %>%
        dplyr::select(region, class_12km) %>%
        group_by(class_12km) %>%
        add_tally() %>%
        dplyr::select(region, class_12km, n) %>%
        distinct() %>%
        ungroup()) %>%
  bind_rows()

n_samples_train


n_samples_train_aux <- n_samples_train |>
  mutate(class_12km = case_when(class_12km == "YES" ~ "Impact", TRUE ~ "No impact"))


plot4 <- ggplot(data = n_samples_train_aux) +
  geom_bar(aes(x=class_12km, y =n, fill = class_12km), stat = "identity") +
  scale_fill_manual(values = c(`No impact`="royalblue4", Impact="indianred1")) +
  facet_wrap(~region, scales = "free", ncol=1) +
  scale_x_discrete(expand = c(0,0)) +
  theme(panel.background = element_rect(fill="white",color="transparent"),
        panel.border = element_rect(fill="transparent",color="black"),
        panel.grid = element_blank(),
        axis.text.x = element_text(size=7.5),
        axis.text.y = element_text(size=7.5),
        strip.text = element_text(size = 7.5, hjust = 0, vjust = 0),
        strip.background = element_rect(fill="transparent", colour="transparent"),
        legend.key.size = unit(0.20,"cm"),
        legend.text.align = 0,
        legend.text=element_text(size=6.5),
        legend.title.align = 0.5,
        legend.title = element_text(size = 6.5),
        legend.margin = margin(unit = "cm", t=0.05,r=0.08,b=0.15,l=0.08),
        legend.box.background = element_rect(fill=alpha('white', 0.2),color="gray30",size = 0.15,),
        legend.background = element_rect(fill=alpha('white', 0.45),color="gray30",size = 0.25))

plot4  
```


```{r}
ggsave(plot = plot4, "G:/My Drive/Postdoc UNAM docs/Renovación posdoc DGAPA/n_samples_train.pdf", units = "cm", width = 6.5, height=26)
```



```{r}
pmp_usage_sampled_clean <- pmp_usage_sampled %>%
  map(~ {
    .x |>
      pivot_longer(cols = -c(ID, region, class_12km)) |>
      filter(value > 0) |>
      inner_join(
        .x |>
          pivot_longer(cols = -c(region, class_12km, ID)) |>
          filter(value > 0) |>
          count(region, class_12km, name) |>
          filter(n >= 2) |>
          dplyr::select(-n), 
        by = c("region", "class_12km", "name")
        ) |>
      group_by(ID) |>
      mutate(value = (value / sum(value)) * 100) |>
      ungroup() |>
      arrange(name) |>
      pivot_wider(id_cols = c(region, class_12km, ID), values_fill = 0)
      
  })

pmp_usage_sampled_clean[["12"]]
```


Obtener el set de entrenamiento para cada zona
```{r}
# Apply the transformation to each dataframe in pmp_usage_sampled
train_data_list <- pmp_usage_sampled_clean %>%
  map(~ { .x %>%
      pivot_longer(cols = -c(region, class_12km, ID), names_to = "name", values_to = "abundance") %>%
      group_by(region, class_12km, name) %>%
      summarise(
        mean_taxa = mean(abundance),
        sd_taxa = sd(abundance),
        .groups = "drop"
      ) %>%
      filter(mean_taxa > 0) |>
      filter(sd_taxa > 0) |>
      pivot_wider(names_from = class_12km, values_from = c(mean_taxa, sd_taxa), values_fill=0) 
  })

# Access a specific transformed dataframe, e.g., for region "13"
aux0 <- train_data_list[["15"]]
aux0

#write.csv(aux0,"train_example.csv")
```



#To obatin the testing dataset
```{r}
# Apply the task to each dataframe in pmp_usage_sampled and pmp_usage_split for each region
test_data_list <- map2(pmp_usage_sampled_clean, pmp_usage_split, ~ {
  
  # Perform the anti_join and transformation for each value
  .y %>%
    anti_join(.x, by = c("ID", "region", "class_12km")) %>%
    ungroup() %>%
    pivot_longer(cols = -c(ID, region, class_12km)) %>%
    filter(value > 0) %>%
    mutate(percent = value * 100) %>%
    dplyr::select(-value) 
})

# Access the transformed data for a specific Value
aux2 <- test_data_list[["13"]]

aux2

unique(test_data_list[["13"]]$ID)
```


```{r}
saveRDS(train_data_list,"Output_train_test_human_footprint/train_data_run1.rds")

saveRDS(test_data_list,"Output_train_test_human_footprint/test_data_run1.rds")
```


```{r}
pmp_usage_sampled 
```


```{r}
train_data_list <- readRDS("Output_train_test_human_footprint/train_data_run1.rds")
#srandom_data_percent <- readRDS("Output_train_test/srandom_data_percent_run1.rds")

pmp_usage_sampled
```


```{r}
#train_data_list[["13"]]
#pmp_usage_sampled[["13"]]

#zona <- unique(train_data_list[["13"]]$zone)
#alto <- "high"
#bajo <- "low"

#top_taxa <- train_data_list[["13"]] %>%
  #dplyr::select(name, !!sym(paste0("mean_taxa_", alto))) %>%
  #arrange(desc(!!sym(paste0("mean_taxa_", alto)))) %>%
  #slice_head(n = 25) |>
  #dplyr::select(name) %>% 
  #distinct() |>
  #pull()

#top_taxa_mean <- train_data_list[["13"]] %>%
  #dplyr::select(name, !!sym(paste0("mean_taxa_", alto))) %>%
  #arrange(desc(!!sym(paste0("mean_taxa_", alto)))) %>%
  #slice_head(n = 25) |>
  #rename(taxa = name, abundance = !!sym(paste0("mean_taxa_", alto)))

#top_taxa_perc <- pmp_usage_sampled[["13"]] %>% 
  #filter(class_12km == alto) |>
  #dplyr::select(ID, Value, class_12km, all_of(top_taxa)) |>
  #pivot_longer(cols = -c(ID,Value,class_12km), names_to = "taxa", values_to = "abundance") |>
  #mutate(abundance = abundance * 100)

#Count positive occurrences (in different samples)
#positive_counts <- pmp_usage_sampled[["13"]] %>% 
  #filter(class_12km == alto) |>
  #dplyr::select(ID, Value, class_12km, all_of(top_taxa)) |>
  #summarise_all(~ sum(. > 0, na.rm = TRUE)) |> 
  #pivot_longer(cols = -c(ID,Value,class_12km)) |>
  #dplyr::select(name,value)

#plot_boxes <- top_taxa_perc |>  
  #ggplot(aes(x = factor(taxa, levels = top_taxa), y = abundance)) + 
  #geom_boxplot(outlier.alpha = 0.1, linewidth = 0.2, outlier.size = 0.2) +
  #geom_point(data = top_taxa_mean, aes(x = factor(taxa, levels = top_taxa), y = abundance), color = "deepskyblue", size = 0.5) +
  #expand_limits(y = c(-8, 80)) +
  #scale_y_continuous(breaks=seq(0, 100, 10)) +
  #geom_text(data = positive_counts, aes(x= name, y = -6, label = value), size=1.8, angle = 60, colour="dodgerblue4") +
  #labs(x="", y="Abundance (%)", subtitle = paste0(zona,": ", alto, sep="")) +
  #theme(plot.title = element_text(size=8),
        #plot.subtitle = element_text(size=8),
        #axis.text.x = element_text(face = "italic",size=9, angle = 90, hjust = 1, vjust = 0.3),
        #axis.text.y = element_text(size=9),
        #axis.title.x = element_text(size=9),
        #axis.title.y = element_text(size=9),
       # plot.caption = element_text(size=9,hjust = 0, face = "bold"),
       # panel.grid.major = element_blank(),
       # panel.grid.minor = element_blank(),
       # panel.background = element_blank(),
       # panel.border = element_rect(colour = "black", fill=NA))

#plot_boxes

```



```{r}
# Define a function to generate the plots and save them
generate_plots <- function(region, YES, NO, train_data_list, pmp_usage_sampled) {
  
  # Get the top taxa for the specified category (alto)
  top_taxa <- train_data_list[[region]] %>%
    dplyr::select(name, !!sym(paste0("mean_taxa_", YES))) %>%
    arrange(desc(!!sym(paste0("mean_taxa_", YES)))) %>%
    slice_head(n = 28) %>%
    dplyr::select(name) %>%
    distinct() %>%
    pull()

  # Create the dataframe with the mean values for the top taxa (for plotting)
  top_taxa_mean <- train_data_list[[region]] %>%
    dplyr::select(name, !!sym(paste0("mean_taxa_", YES))) %>%
    arrange(desc(!!sym(paste0("mean_taxa_", YES)))) %>%
    slice_head(n = 28) %>%
    rename(taxa = name, abundance = !!sym(paste0("mean_taxa_", YES)))
  
  # Create the dataframe with the percentage values for the top taxa
  top_taxa_perc <- pmp_usage_sampled[[region]] %>% 
    filter(class_12km == YES) %>%
    dplyr::select(ID, region, class_12km, all_of(top_taxa)) %>%
    pivot_longer(cols = -c(ID, region, class_12km), names_to = "taxa", values_to = "abundance") %>%
    mutate(abundance = abundance * 100)
 
  # Count positive occurrences for each top taxa
  positive_counts <- pmp_usage_sampled[[region]] %>%
    filter(class_12km == YES) %>%
    dplyr::select(ID, region, class_12km, all_of(top_taxa)) %>%
    summarise_all(~ sum(. > 0, na.rm = TRUE)) %>%
    pivot_longer(cols = -c(ID, region, class_12km)) %>%
    dplyr::select(name, value)
  
  # Generate the boxplot for the top taxa
  plot_boxes <- top_taxa_perc %>%  
    ggplot(aes(x = factor(taxa, levels = top_taxa), y = abundance)) + 
    geom_boxplot(outlier.alpha = 0.1, linewidth = 0.2, outlier.size = 0.2) +
    geom_point(data = top_taxa_mean, aes(x = factor(taxa, levels = top_taxa), y = abundance), color = "deepskyblue", size = 0.5) +
    expand_limits(y = c(-8, 80)) +
    scale_y_continuous(breaks = seq(0, 100, 10)) +
    geom_text(data = positive_counts, aes(x = name, y = -6, label = value), size = 1.8, angle = 60, colour = "dodgerblue4") +
    labs(x = "", y = "Abundance (%)", subtitle = paste0(region, ": ", YES)) +
    theme(plot.title = element_text(size = 8),
          plot.subtitle = element_text(size = 8),
          axis.text.x = element_text(face = "italic", size = 9, angle = 90, hjust = 1, vjust = 0.3),
          axis.text.y = element_text(size = 9),
          axis.title.x = element_text(size = 9),
          axis.title.y = element_text(size = 9),
          plot.caption = element_text(size = 9, hjust = 0, face = "bold"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_rect(colour = "black", fill = NA))
  
  # Save the plot as a file
  ggsave(paste0("Output_figures_human_footprint/plot_", region, "_", YES, ".png"), plot = plot_boxes, units="cm", width = 10, height = 10)
}

# Iterate through all zones and categories ("high" and "low") and generate/save the plots
regions <- names(train_data_list)  # Get all zones
categories <- c("YES", "NO")  # Categories

for (region in regions) {
  for (category in categories) {
    generate_plots(region, category, category, train_data_list, pmp_usage_sampled)
  }
}
```



```{r}


```




