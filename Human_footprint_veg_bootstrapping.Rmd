---
title: "Untitled"
output: html_document
date: "2024-12-02"
---

#Workflow for evaluating the categorical predictive model 

```{r}
library(tidyverse)
```


```{r}
pmp_usage_split <- readRDS("Output_data_human_footprint/pmp_usage_split.rds")
```




```{r}
evaluate_model <- function(seed, pmp_usage_split) {
  set.seed(seed)
  
  # Split the data
  pmp_usage_sampled <- pmp_usage_split %>%
    map(~ .x %>%
          group_by(class_12km) %>%
          slice_sample(prop = 0.7) %>%
          ungroup())
  
  # Generate training data
  train_data_list <- pmp_usage_sampled %>% 
    map(~ {
      .x %>%
        pivot_longer(cols = -c(region, class_12km, ID), names_to = "name", values_to = "abundance") %>%
        mutate(abundance = abundance * 100) %>%
        group_by(region, class_12km, name) %>%
        summarise(
          mean_taxa = mean(abundance),
          sd_taxa = sd(abundance),
          .groups = "drop"
        ) %>%
        filter(mean_taxa > 0) |>
        filter(sd_taxa > 0) |>
        pivot_wider(names_from = class_12km, values_from = c(mean_taxa, sd_taxa),values_fill = 0) 
    })
  
  # Test data
  test_data_list <- map2(pmp_usage_sampled, pmp_usage_split, ~ {
    .y %>%
      anti_join(.x, by = c("ID", "region", "class_12km")) %>%
      ungroup() %>%
      pivot_longer(cols = -c(ID, region, class_12km)) %>%
      filter(value > 0) %>%
      mutate(percent = value * 100) %>%
      dplyr::select(-value) 
  })
  

  # Generate the evaluation results
  all_results <- map(names(test_data_list),~ {
    stest_df <- test_data_list[[.]]
    strain_df <- train_data_list[[.]]
    
    all <- full_join(
      stest_df,
      dplyr::select(strain_df, -region),
      by = "name"
    ) %>%
      filter(!is.na(percent)) %>%  
      filter(!is.na(mean_taxa_YES))
      
    dis_index <- all %>%
      mutate(Epsilon = 0.5) %>%
      mutate(YES_Sqrt = (percent - mean_taxa_YES)^2 / ((sd_taxa_YES + Epsilon)^2)) %>%
      mutate(NO_Sqrt = (percent - mean_taxa_NO)^2 / ((sd_taxa_NO + Epsilon)^2)) %>%
      dplyr::select(ID, class_12km, name, YES_Sqrt, NO_Sqrt) %>%
      group_by(ID) %>%
      summarise(across(c(YES_Sqrt, NO_Sqrt), sum)) %>%
      mutate(across(c(YES_Sqrt, NO_Sqrt), sqrt)) %>%
      ungroup()
    
    simi_index <- dis_index %>%
      mutate(YES = exp(-YES_Sqrt / 100)) %>%
      mutate(NO = exp(-NO_Sqrt / 100)) %>%
      dplyr::select(ID, YES, NO)
    
    sqsc <- simi_index %>%
      pivot_longer(cols = -(ID), names_to = "predicted_class") %>%
      group_by(ID) %>%
      slice_max(value) %>%
      ungroup()
    
    pred_biome <- distinct(dplyr::select(stest_df, region,ID,class_12km)) %>%
      inner_join(sqsc, by = "ID") %>%
      dplyr::select(-value)
    
    observed <- ordered(pred_biome$class_12km, levels = c('YES', 'NO'))
    predicted <- ordered(pred_biome$predicted_class, levels = c('YES', 'NO'))
    
    accuracy <- mlr3measures::acc(observed, predicted) * 100
    balanced_accuracy <- mlr3measures::bacc(observed, predicted) * 100
    
    list(
      Accuracy = accuracy,
      Balanced_accuracy = balanced_accuracy,
      Region = unique(stest_df$region)
    )
  })
  
  metrics <- map_dfr(all_results, ~ data.frame(Accuracy = .x$Accuracy, 
                                               Balanced_accuracy = .x$Balanced_accuracy,
                                               Region = .x$Region))
  metrics
}
```


#Apply the function
This code is performing **n** iterations of the `evaluate_model()` function, each with a different seed (random initialization).
It then combines the results into a single dataframe, with each iteration labeled by the "iteration" column. This allows for easy comparison across different random seeds.

```{r}
# Set the seed for random number generation to ensure reproducibility of results.
# This means every time the code is run, the random processes will produce the same results.
set.seed(189)

# Generate a vector of 5 random integers between 1 and 1,000,000. 
# These will be used as different random seeds for each iteration of the model evaluation.
seeds <- sample(1:1e6, 3)

# Apply the `evaluate_model()` function to each seed in the `seeds` vector, 
# - `map_dfr()` is a purrr function that iterates over each seed, applies `evaluate_model()` to it, 
#   and combines the results into a single dataframe (`.dfr` stands for "data frame row binding").
# - The `~` syntax is used for a formula, which applies the `evaluate_model` function to each element `.x` of the `seeds` vector.
# - The `pmp_usage_split` argument is passed to `evaluate_model()` along with each seed.
# - `.id = "iteration"` adds an additional column to the resulting dataframe that indicates which iteration (or seed) the row belongs to.
results <- map_dfr(seeds, ~ evaluate_model(.x, pmp_usage_split), .id = "iteration")
```


```{r}
saveRDS(results, "Output_data_results_human_footprint/results_iteration_1.rds")
```



```{r}
summary_metrics <- results %>%
  group_by(Region) %>%
  summarise(
    Mean_Accuracy = mean(Accuracy, na.rm = TRUE),
    SD_Accuracy = sd(Accuracy, na.rm = TRUE),
    Mean_Balanced_Accuracy = mean(Balanced_accuracy, na.rm = TRUE),
    SD_Balanced_Accuracy = sd(Balanced_accuracy, na.rm = TRUE)
  )
```






```{r}
results |>
  ggplot() + 
  geom_density(aes(x = Balanced_accuracy, fill=Region, colour=Region), alpha = .8) +
  # Add a vertical line for the mean of each Region
  geom_vline(data = results |> group_by(Region) |> summarise(mean_accuracy = mean(Accuracy)),
             aes(xintercept = mean_accuracy), color = "black", linetype = "dashed", size = 1) +
  # Add text for the mean value for each Region
  geom_text(data = results |> group_by(Region) |> summarise(mean_accuracy = mean(Accuracy)),
            aes(x = mean_accuracy, y = 0.02, label = round(mean_accuracy, 2)),
            color = "black", angle = 90, hjust = -0.08, vjust = 1) +
  facet_wrap(~Region) +
  jcolors::scale_color_jcolors(palette = "pal9") +
  jcolors::scale_fill_jcolors(palette = "pal9") +
  theme(panel.background = element_rect(fill="transparent", colour="gray80"),
        strip.background = element_rect(fill="transparent", colour="gray80"))

results |>
  ggplot(aes(x = Balanced_accuracy, fill=Region, colour=Region)) + 
  geom_density(alpha = .7) +
  jcolors::scale_color_jcolors(palette = "pal9") +
  jcolors::scale_fill_jcolors(palette = "pal9") +
  labs(title = "Balanced accuracy") +
  theme_test()

results |>
  ggplot(aes(x = Balanced_accuracy, fill=Region, colour=Region)) + 
  geom_density(alpha = 1) +
  facet_wrap(~Region) +
  jcolors::scale_color_jcolors(palette = "pal9") +
  jcolors::scale_fill_jcolors(palette = "pal9") +
  labs(title = "Balanced accuracy") +
  theme_test()
```


```{r}
# Calculate the mean of Balanced_accuracy
mean_balance_accuracy <- mean(results$Balanced_accuracy)

# Plot with density and mean line
results |>
  ggplot(aes(x = Balanced_accuracy)) + 
  geom_density(alpha = .7, fill = "#800080", colour = "#800080") +
  geom_vline(aes(xintercept = mean_balance_accuracy), 
             color = "white", linetype = "dashed", size = 1) +
  annotate("text", x = mean_balance_accuracy + 1, y = 0.02, 
           label = paste("Mean =", round(mean_balance_accuracy, 2)), 
           color = "white", size = 5, hjust = 0) +
  labs(title = "All regions Balanced accuracy") +
  theme_test()
```






